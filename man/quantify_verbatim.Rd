% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/quantify_verbatim.R
\name{quantify_verbatim}
\alias{quantify_verbatim}
\title{Creates exploratory plots of the assignment of sentiments to words}
\usage{
quantify_verbatim(surveydata, tidydata, id = id, quant_var,
  min_occur = 3, min_phrases = 25, max_phrases = 80,
  pval_limit = 0.1, xreg = c(), remove_stop = TRUE)
}
\arguments{
\item{surveydata}{Data frame with the survey data}

\item{tidydata}{Data frame with the unnested phrases (usually from tidy_verbatim())}

\item{id}{Unique survey id. By default, can be omitted if column is named 'id'}

\item{quant_var}{Numerical column in survey data frame on which phrases will be regressed}

\item{min_occur}{Number of times a phrase must occur to be included}

\item{min_phrases}{Force the plot to include at least this many phrases}

\item{max_phrases}{Maximum number of phrases to show in plot}

\item{pval_limit}{Threshold from 0 - 1. Phrases below the threshold will be highlighted
on the plot. Default is 0.1}

\item{xreg}{Optional list of columns from survey data frame to be used as additional
control variables in regression}

\item{remove_stop}{Do you want to remove common "stop-words"? Applies only to
single-word phrases ("unigrams"). If so, use TRUE}
}
\description{
Creates and prints ggplots showing how the sentiment assignment works.
One or more plots can be displayed depending on the user preference.
}
\details{
The first plot, "sentiment_histogram", shows a histogram for each sentiment
and question. It shows the distribution of the sentiment by the frequency
of occurences
}
